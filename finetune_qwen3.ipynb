{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadp1001/kaggle_payground_prediction_s5e6/blob/main/S5E6_XGBoost_0601.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7069b9b9bc40405a8b49967c77b78bd0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggleâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "playground_series_s5e6_path = kagglehub.competition_download('jigsaw-agile-community-rules')\n",
        "print('Data source import complete.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface_hub version: 0.33.1\n",
            "tokenizers version: 0.21.2\n",
            "torch version: 2.6.0+cu124\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "pkgs = [\n",
        "    \"huggingface_hub\",  # to download pretrained weights\n",
        "    \"tokenizers\",       # to implement the tokenizer\n",
        "    \"torch\",            # to implement the model\n",
        "]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")\n",
        "\n",
        "import json\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from pathlib import Path\n",
        "from safetensors.torch import load_file\n",
        "from huggingface_hub import hf_hub_download, snapshot_download\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Turn off reasoning capabilities for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "USE_REASONING_MODEL = False\n",
        "CHOOSE_MODEL = \"0.6B\"\n",
        "QWEN3_CONFIG = {\n",
        "        \"vocab_size\": 151_936,           # Vocabulary size\n",
        "        \"context_length\": 40_960,        # Context length that was used to train the model\n",
        "        \"emb_dim\": 1024,                 # Embedding dimension\n",
        "        \"n_heads\": 16,                   # Number of attention heads\n",
        "        \"n_layers\": 28,                  # Number of layers\n",
        "        \"hidden_dim\": 3072,              # Size of the intermediate dimension in FeedForward\n",
        "        \"head_dim\": 128,                 # Size of the heads in GQA\n",
        "        \"qk_norm\": True,                 # Whether to normalize queries and values in GQA\n",
        "        \"n_kv_groups\": 8,                # Key-Value groups for grouped-query attention\n",
        "        \"rope_base\": 1_000_000.0,        # The base in RoPE's \"theta\"\n",
        "        \"dtype\": torch.bfloat16,         # Lower-precision dtype to reduce memory usage\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(cfg[\"emb_dim\"], cfg[\"hidden_dim\"], dtype=cfg[\"dtype\"], bias=False)\n",
        "        self.fc2 = nn.Linear(cfg[\"emb_dim\"], cfg[\"hidden_dim\"], dtype=cfg[\"dtype\"], bias=False)\n",
        "        self.fc3 = nn.Linear(cfg[\"hidden_dim\"], cfg[\"emb_dim\"], dtype=cfg[\"dtype\"], bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_fc1 = self.fc1(x)\n",
        "        x_fc2 = self.fc2(x)\n",
        "        x = nn.functional.silu(x_fc1) * x_fc2\n",
        "        return self.fc3(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RMSNorm(nn.Module):\n",
        "    def __init__(self, emb_dim, eps=1e-6, bias=False, qwen3_compatible=True):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.qwen3_compatible = qwen3_compatible\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim)) if bias else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        input_dtype = x.dtype\n",
        "\n",
        "        if self.qwen3_compatible:\n",
        "            x = x.to(torch.float32)\n",
        "\n",
        "        variance = x.pow(2).mean(dim=-1, keepdim=True)\n",
        "        norm_x = x * torch.rsqrt(variance + self.eps)\n",
        "        norm_x = norm_x * self.scale\n",
        "\n",
        "        if self.shift is not None:\n",
        "            norm_x = norm_x + self.shift\n",
        "\n",
        "        return norm_x.to(input_dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_rope_params(head_dim, theta_base=10_000, context_length=4096, dtype=torch.float32):\n",
        "    assert head_dim % 2 == 0, \"Embedding dimension must be even\"\n",
        "\n",
        "    # Compute the inverse frequencies\n",
        "    inv_freq = 1.0 / (theta_base ** (torch.arange(0, head_dim, 2, dtype=dtype)[: (head_dim // 2)].float() / head_dim))\n",
        "\n",
        "    # Generate position indices\n",
        "    positions = torch.arange(context_length, dtype=dtype)\n",
        "\n",
        "    # Compute the angles\n",
        "    angles = positions[:, None] * inv_freq[None, :]  # Shape: (context_length, head_dim // 2)\n",
        "\n",
        "    # Expand angles to match the head_dim\n",
        "    angles = torch.cat([angles, angles], dim=1)  # Shape: (context_length, head_dim)\n",
        "\n",
        "    # Precompute sine and cosine\n",
        "    cos = torch.cos(angles)\n",
        "    sin = torch.sin(angles)\n",
        "\n",
        "    return cos, sin\n",
        "\n",
        "\n",
        "def apply_rope(x, cos, sin):\n",
        "    # x: (batch_size, num_heads, seq_len, head_dim)\n",
        "    batch_size, num_heads, seq_len, head_dim = x.shape\n",
        "    assert head_dim % 2 == 0, \"Head dimension must be even\"\n",
        "\n",
        "    # Split x into first half and second half\n",
        "    x1 = x[..., : head_dim // 2]  # First half\n",
        "    x2 = x[..., head_dim // 2 :]  # Second half\n",
        "\n",
        "    # Adjust sin and cos shapes\n",
        "    cos = cos[:seq_len, :].unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, seq_len, head_dim)\n",
        "    sin = sin[:seq_len, :].unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "    # Apply the rotary transformation\n",
        "    rotated = torch.cat((-x2, x1), dim=-1)\n",
        "    x_rotated = (x * cos) + (rotated * sin)\n",
        "\n",
        "    # It's ok to use lower-precision after applying cos and sin rotation\n",
        "    return x_rotated.to(dtype=x.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GroupedQueryAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self, d_in, num_heads, num_kv_groups, head_dim=None, qk_norm=False, dtype=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert num_heads % num_kv_groups == 0, \"num_heads must be divisible by num_kv_groups\"\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.num_kv_groups = num_kv_groups\n",
        "        self.group_size = num_heads // num_kv_groups\n",
        "\n",
        "        if head_dim is None:\n",
        "            assert d_in % num_heads == 0, \"`d_in` must be divisible by `num_heads` if `head_dim` is not set\"\n",
        "            head_dim = d_in // num_heads\n",
        "\n",
        "        self.head_dim = head_dim\n",
        "        self.d_out = num_heads * head_dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, self.d_out, bias=False, dtype=dtype)\n",
        "        self.W_key = nn.Linear(d_in, num_kv_groups * head_dim, bias=False, dtype=dtype)\n",
        "        self.W_value = nn.Linear(d_in, num_kv_groups * head_dim, bias=False, dtype=dtype)\n",
        "\n",
        "        self.out_proj = nn.Linear(self.d_out, d_in, bias=False, dtype=dtype)\n",
        "\n",
        "        if qk_norm:\n",
        "            self.q_norm = RMSNorm(head_dim, eps=1e-6)\n",
        "            self.k_norm = RMSNorm(head_dim, eps=1e-6)\n",
        "        else:\n",
        "            self.q_norm = self.k_norm = None\n",
        "\n",
        "    def forward(self, x, mask, cos, sin):\n",
        "        b, num_tokens, _ = x.shape\n",
        "\n",
        "        # Apply projections\n",
        "        queries = self.W_query(x)  # (b, num_tokens, num_heads * head_dim)\n",
        "        keys = self.W_key(x)       # (b, num_tokens, num_kv_groups * head_dim)\n",
        "        values = self.W_value(x)   # (b, num_tokens, num_kv_groups * head_dim)\n",
        "\n",
        "        # Reshape\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        keys = keys.view(b, num_tokens, self.num_kv_groups, self.head_dim).transpose(1, 2)\n",
        "        values = values.view(b, num_tokens, self.num_kv_groups, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # Optional normalization\n",
        "        if self.q_norm:\n",
        "            queries = self.q_norm(queries)\n",
        "        if self.k_norm:\n",
        "            keys = self.k_norm(keys)\n",
        "\n",
        "        # Apply RoPE\n",
        "        queries = apply_rope(queries, cos, sin)\n",
        "        keys = apply_rope(keys, cos, sin)\n",
        "\n",
        "        # Expand K and V to match number of heads\n",
        "        keys = keys.repeat_interleave(self.group_size, dim=1)\n",
        "        values = values.repeat_interleave(self.group_size, dim=1)\n",
        "\n",
        "        # Attention\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "        attn_scores = attn_scores.masked_fill(mask, -torch.inf)\n",
        "        attn_weights = torch.softmax(attn_scores / self.head_dim**0.5, dim=-1)\n",
        "\n",
        "        context = (attn_weights @ values).transpose(1, 2).reshape(b, num_tokens, self.d_out)\n",
        "        return self.out_proj(context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = GroupedQueryAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            head_dim=cfg[\"head_dim\"],\n",
        "            num_kv_groups=cfg[\"n_kv_groups\"],\n",
        "            qk_norm=cfg[\"qk_norm\"],\n",
        "            dtype=cfg[\"dtype\"]\n",
        "        )\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
        "        self.norm2 = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
        "\n",
        "    def forward(self, x, mask, cos, sin):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x, mask, cos, sin)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed-forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Qwen3Model(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "\n",
        "        # Main model parameters\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"], dtype=cfg[\"dtype\"])\n",
        "\n",
        "        self.trf_blocks = nn.ModuleList(  # ModuleList since Sequential can only accept one input, and we need `x, mask, cos, sin`\n",
        "            [TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "        )\n",
        "\n",
        "        self.final_norm = RMSNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False, dtype=cfg[\"dtype\"])\n",
        "\n",
        "        # Reusuable utilities\n",
        "        if cfg[\"head_dim\"] is None:\n",
        "            head_dim = cfg[\"emb_dim\"] // cfg[\"n_heads\"]\n",
        "        else:\n",
        "            head_dim = cfg[\"head_dim\"]\n",
        "        cos, sin = compute_rope_params(\n",
        "            head_dim=head_dim,\n",
        "            theta_base=cfg[\"rope_base\"],\n",
        "            context_length=cfg[\"context_length\"]\n",
        "        )\n",
        "        self.register_buffer(\"cos\", cos, persistent=False)\n",
        "        self.register_buffer(\"sin\", sin, persistent=False)\n",
        "        self.cfg = cfg\n",
        "\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        # Forward pass\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        x = tok_embeds\n",
        "\n",
        "        num_tokens = x.shape[1]\n",
        "        mask = torch.triu(torch.ones(num_tokens, num_tokens, device=x.device, dtype=torch.bool), diagonal=1)\n",
        "        \n",
        "        for block in self.trf_blocks:\n",
        "            x = block(x, mask, self.cos, self.sin)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x.to(self.cfg[\"dtype\"]))\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "model = Qwen3Model(QWEN3_CONFIG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Qwen3Model(\n",
              "  (tok_emb): Embedding(151936, 1024)\n",
              "  (trf_blocks): ModuleList(\n",
              "    (0-27): 28 x TransformerBlock(\n",
              "      (att): GroupedQueryAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=2048, bias=False)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "        (out_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
              "        (q_norm): RMSNorm()\n",
              "        (k_norm): RMSNorm()\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (fc1): Linear(in_features=1024, out_features=3072, bias=False)\n",
              "        (fc2): Linear(in_features=1024, out_features=3072, bias=False)\n",
              "        (fc3): Linear(in_features=3072, out_features=1024, bias=False)\n",
              "      )\n",
              "      (norm1): RMSNorm()\n",
              "      (norm2): RMSNorm()\n",
              "    )\n",
              "  )\n",
              "  (final_norm): RMSNorm()\n",
              "  (out_head): Linear(in_features=1024, out_features=2, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_weights_into_qwen(model, param_config, params):\n",
        "    def assign(left, right, tensor_name=\"unknown\"):\n",
        "        if left.shape != right.shape:\n",
        "            raise ValueError(f\"Shape mismatch in tensor '{tensor_name}'. Left: {left.shape}, Right: {right.shape}\")\n",
        "        return torch.nn.Parameter(right.clone().detach() if isinstance(right, torch.Tensor) else torch.tensor(right))\n",
        "\n",
        "    model.tok_emb.weight = assign(model.tok_emb.weight, params[\"model.embed_tokens.weight\"], \"model.embed_tokens.weight\")\n",
        "\n",
        "    for l in range(param_config[\"n_layers\"]):\n",
        "        block = model.trf_blocks[l]\n",
        "        att = block.att\n",
        "\n",
        "        # Q, K, V projections\n",
        "        att.W_query.weight = assign(\n",
        "            att.W_query.weight,\n",
        "            params[f\"model.layers.{l}.self_attn.q_proj.weight\"],\n",
        "            f\"model.layers.{l}.self_attn.q_proj.weight\"\n",
        "        )\n",
        "        att.W_key.weight = assign(\n",
        "            att.W_key.weight,\n",
        "            params[f\"model.layers.{l}.self_attn.k_proj.weight\"],\n",
        "            f\"model.layers.{l}.self_attn.k_proj.weight\"\n",
        "        )\n",
        "        att.W_value.weight = assign(\n",
        "            att.W_value.weight,\n",
        "            params[f\"model.layers.{l}.self_attn.v_proj.weight\"],\n",
        "            f\"model.layers.{l}.self_attn.v_proj.weight\"\n",
        "        )\n",
        "\n",
        "        # Output projection\n",
        "        att.out_proj.weight = assign(\n",
        "            att.out_proj.weight,\n",
        "            params[f\"model.layers.{l}.self_attn.o_proj.weight\"],\n",
        "            f\"model.layers.{l}.self_attn.o_proj.weight\"\n",
        "        )\n",
        "\n",
        "        # QK norms\n",
        "        if hasattr(att, \"q_norm\") and att.q_norm is not None:\n",
        "            att.q_norm.scale = assign(\n",
        "                att.q_norm.scale,\n",
        "                params[f\"model.layers.{l}.self_attn.q_norm.weight\"],\n",
        "                f\"model.layers.{l}.self_attn.q_norm.weight\"\n",
        "            )\n",
        "        if hasattr(att, \"k_norm\") and att.k_norm is not None:\n",
        "            att.k_norm.scale = assign(\n",
        "                att.k_norm.scale,\n",
        "                params[f\"model.layers.{l}.self_attn.k_norm.weight\"],\n",
        "                f\"model.layers.{l}.self_attn.k_norm.weight\"\n",
        "            )\n",
        "\n",
        "        # Attention layernorm\n",
        "        block.norm1.scale = assign(\n",
        "            block.norm1.scale,\n",
        "            params[f\"model.layers.{l}.input_layernorm.weight\"],\n",
        "            f\"model.layers.{l}.input_layernorm.weight\"\n",
        "        )\n",
        "\n",
        "        # Feedforward weights\n",
        "        block.ff.fc1.weight = assign(\n",
        "            block.ff.fc1.weight,\n",
        "            params[f\"model.layers.{l}.mlp.gate_proj.weight\"],\n",
        "            f\"model.layers.{l}.mlp.gate_proj.weight\"\n",
        "        )\n",
        "        block.ff.fc2.weight = assign(\n",
        "            block.ff.fc2.weight,\n",
        "            params[f\"model.layers.{l}.mlp.up_proj.weight\"],\n",
        "            f\"model.layers.{l}.mlp.up_proj.weight\"\n",
        "        )\n",
        "        block.ff.fc3.weight = assign(\n",
        "            block.ff.fc3.weight,\n",
        "            params[f\"model.layers.{l}.mlp.down_proj.weight\"],\n",
        "            f\"model.layers.{l}.mlp.down_proj.weight\"\n",
        "        )\n",
        "        block.norm2.scale = assign(\n",
        "            block.norm2.scale,\n",
        "            params[f\"model.layers.{l}.post_attention_layernorm.weight\"],\n",
        "            f\"model.layers.{l}.post_attention_layernorm.weight\"\n",
        "        )\n",
        "\n",
        "    # Final normalization and output head\n",
        "    model.final_norm.scale = assign(model.final_norm.scale, params[\"model.norm.weight\"], \"model.norm.weight\")\n",
        "\n",
        "    if \"lm_head.weight\" in params:\n",
        "        model.out_head.weight = assign(model.out_head.weight, params[\"lm_head.weight\"], \"lm_head.weight\")\n",
        "    else:\n",
        "        # Model uses weight tying, hence we reuse the embedding layer weights here\n",
        "        print(\"Model uses weight tying.\")\n",
        "        model.out_head.weight = assign(model.out_head.weight, params[\"model.embed_tokens.weight\"], \"model.embed_tokens.weight\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bd520220dfb48c28581c3e3b62acb69",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.19G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model uses weight tying.\n"
          ]
        }
      ],
      "source": [
        "if USE_REASONING_MODEL:\n",
        "    repo_id = f\"Qwen/Qwen3-{CHOOSE_MODEL}\"\n",
        "else:\n",
        "    repo_id = f\"Qwen/Qwen3-{CHOOSE_MODEL}-Base\"\n",
        "\n",
        "local_dir = Path(repo_id).parts[-1]\n",
        "\n",
        "if CHOOSE_MODEL == \"0.6B\":\n",
        "    weights_file = hf_hub_download(\n",
        "        repo_id=repo_id,\n",
        "        filename=\"model.safetensors\",\n",
        "        local_dir=local_dir,\n",
        "    )\n",
        "    weights_dict = load_file(weights_file)\n",
        "else:\n",
        "    repo_dir = snapshot_download(repo_id=repo_id, local_dir=local_dir)\n",
        "    index_path = os.path.join(repo_dir, \"model.safetensors.index.json\")\n",
        "    with open(index_path, \"r\") as f:\n",
        "        index = json.load(f)\n",
        "\n",
        "    weights_dict = {}\n",
        "    for filename in set(index[\"weight_map\"].values()):\n",
        "        shard_path = os.path.join(repo_dir, filename)\n",
        "        shard = load_file(shard_path)\n",
        "        weights_dict.update(shard)\n",
        "\n",
        "load_weights_into_qwen(model, QWEN3_CONFIG, weights_dict)\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(-torch.inf).to(logits.device), logits)\n",
        "\n",
        "        # Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if eos_id is not None and idx_next.item() == eos_id:\n",
        "            break  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "614bfc670e924508b0bc579aaa08a74f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/174 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b08aa226ea2c4945bf027980e7381865",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenization_qwen.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-7B:\n",
            "- tokenization_qwen.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f57d956e9510463abade14572d4a3a16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "qwen.tiktoken: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen-7B', trust_remote_code=True, pad_token='<|endoftext|>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Give me a short introduction to large language models.'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"Give me a short introduction to large language models.\"\n",
        "\n",
        "input_token_ids = tokenizer.encode(prompt)\n",
        "text = tokenizer.decode(input_token_ids)\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 11.59 sec\n",
            "Max memory allocated: 1.49 GB\n",
            "Give me a short introduction to large language models. Large language models are advanced artificial intelligence systems that use deep learning techniques to understand and generate human-like text. They are trained on vast amounts of text data, allowing them to perform a wide range of tasks, from answering questions to writing essays, composing poetry, and even creating music. These models have revolutionized the way we interact with technology, enabling machines to simulate human language and perform complex tasks with remarkable accuracy.<|endoftext|>Human language is a complex and dynamic system that has evolved over thousands of years. It is characterized by its ability to convey meaning, express emotions, and communicate ideas across different cultures and languages. Despite its complexity, human language is also highly adaptable and can be used to solve problems, make decisions, and engage in social interactions. Large language...\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "torch.manual_seed(123)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "output_token_ids = generate(\n",
        "    model=model,\n",
        "    idx=torch.tensor(input_token_ids, device=device).unsqueeze(0),\n",
        "    max_new_tokens=150,\n",
        "    context_size=QWEN3_CONFIG[\"context_length\"],\n",
        "    top_k=1,\n",
        "    temperature=0.\n",
        ")\n",
        "\n",
        "print(f\"Time: {time.time() - start:.2f} sec\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    max_mem_bytes = torch.cuda.max_memory_allocated()\n",
        "    max_mem_gb = max_mem_bytes / (1024 ** 3)\n",
        "    print(f\"Max memory allocated: {max_mem_gb:.2f} GB\")\n",
        "\n",
        "output_text = tokenizer.decode(output_token_ids.squeeze(0).tolist())\n",
        "\n",
        "print(output_text + \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that model is able to generate coherent text. Next we will modify the last layer to preparte it for classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Qwen3Model(\n",
              "  (tok_emb): Embedding(151936, 1024)\n",
              "  (trf_blocks): ModuleList(\n",
              "    (0-27): 28 x TransformerBlock(\n",
              "      (att): GroupedQueryAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=2048, bias=False)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "        (out_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
              "        (q_norm): RMSNorm()\n",
              "        (k_norm): RMSNorm()\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (fc1): Linear(in_features=1024, out_features=3072, bias=False)\n",
              "        (fc2): Linear(in_features=1024, out_features=3072, bias=False)\n",
              "        (fc3): Linear(in_features=3072, out_features=1024, bias=False)\n",
              "      )\n",
              "      (norm1): RMSNorm()\n",
              "      (norm2): RMSNorm()\n",
              "    )\n",
              "  )\n",
              "  (final_norm): RMSNorm()\n",
              "  (out_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.out_head = nn.Linear(QWEN3_CONFIG[\"emb_dim\"], 2, bias=False, dtype=QWEN3_CONFIG[\"dtype\"]).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's also add final RMSNorm and transformer layer to training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "for param in model.trf_blocks[-1].parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.final_norm.parameters():\n",
        "    param.requires_grad = False    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calc_auc_metric(input_batch, target_batch,device):\n",
        "    \"\"\"Calculates the ROC-AUC metric for a batch of inputs and targets.\n",
        "    \n",
        "    :param input_batch: Tensor of shape (batch_size, sequence_length) containing input token IDs.\n",
        "    :param target_batch: Tensor of shape (batch_size,) containing binary target labels (0 or 1).\n",
        "    :param device: The device (CPU or GPU) to perform computations on\"\"\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    input_batch = input_batch.to(device)\n",
        "    target_batch = target_batch.to(device)\n",
        "    amp_ctx = torch.amp.autocast(device_type='cuda',dtype=QWEN3_CONFIG[\"dtype\"])\n",
        "    \n",
        "    with torch.inference_mode(), amp_ctx:\n",
        "        logits = model(input_batch)[:,-1,:]\n",
        "        \n",
        "    probs = torch.softmax(logits, dim=-1)[:,1].detach().cpu().numpy() # Probability of positive class\n",
        "    target_batch = target_batch.detach().cpu().numpy()\n",
        "    return roc_auc_score(target_batch, probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cal_auc_loader(model, data_loader, device):\n",
        "    \"\"\"Calculates the ROC-AUC metric for a DataLoader.\n",
        "    \n",
        "    :param model: The model to evaluate.\n",
        "    :param data_loader: DataLoader providing batches of (input_batch, target_batch).\n",
        "    :param device: The device (CPU or GPU) to perform computations on.\"\"\"\n",
        "    model.eval()\n",
        "    all_probs = []\n",
        "    all_targets = []\n",
        "    amp_ctx = torch.amp.autocast(device_type='cuda',dtype=QWEN3_CONFIG[\"dtype\"])\n",
        "\n",
        "    with torch.inference_mode(), amp_ctx:\n",
        "        for input_batch, target_batch in data_loader:\n",
        "            input_batch = input_batch.to(device)\n",
        "            target_batch = target_batch.to(device)\n",
        "            logits = model(input_batch)[:,-1,:]\n",
        "            probs = torch.softmax(logits, dim=-1)[:,1].detach().cpu().numpy() # Probability of positive class\n",
        "            all_probs.extend(probs)\n",
        "            all_targets.extend(target_batch.detach().cpu().numpy())\n",
        "    return roc_auc_score(all_targets, all_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model):\n",
        "    \"\"\"Returns SUM of cross-entropy losses over the batch (for proper global averaging).\n",
        "    \n",
        "    :param input_batch: Tensor of shape (batch_size, sequence_length) containing input token IDs.\n",
        "    :param target_batch: Tensor of shape (batch_size,) containing target class indices.\n",
        "    :param model: The model to evaluate.\n",
        "    :param device: The device (CPU or GPU) to perform computations on.\"\"\"\n",
        "    model.eval()\n",
        "    input_batch = input_batch.to(model.out_head.weight.device)\n",
        "    target_batch = target_batch.to(model.out_head.weight.device)\n",
        "    logits = model(input_batch)\n",
        "    logits = logits[:, -1, :]  \n",
        "    loss_sum = F.cross_entropy(logits, target_batch, reduction=\"sum\")\n",
        "    return loss_sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calc_loss_loader(model, data_loader, device):\n",
        "    \"\"\"Calculates the average cross-entropy loss for a DataLoader.\n",
        "    :param model: The model to evaluate.\n",
        "    :param data_loader: DataLoader providing batches of (input_batch, target_batch).\n",
        "    :param device: The device (CPU or GPU) to perform computations on.\"\"\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    amp_ctx = torch.amp.autocast(device_type='cuda',dtype=QWEN3_CONFIG[\"dtype\"])\n",
        "\n",
        "    with torch.inference_mode(), amp_ctx:\n",
        "        for input_batch, target_batch in data_loader:\n",
        "            input_batch = input_batch.to(device, non_blocking=True)\n",
        "            target_batch = target_batch.to(device, non_blocking=True)\n",
        "\n",
        "            batch_loss_sum = calc_loss_batch(input_batch, target_batch, model)\n",
        "            total_loss += float(batch_loss_sum)\n",
        "            total_samples += target_batch.size(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, train_loader, optimizer, device):\n",
        "    \"\"\"Trains the model for one epoch.\n",
        "    \n",
        "     :param model: The model to train.\n",
        "     :param train_loader: DataLoader providing batches of (input_batch, target_batch).\n",
        "     :param optimizer: The optimizer to use for training.\n",
        "     :param device: The device (CPU or GPU) to perform computations on.\"\"\"\n",
        "    total_loss = 0.0\n",
        "    for input_batch, target_batch in train_loader:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        loss = calc_loss_batch(input_batch, target_batch, model)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * input_batch.size(0)  # Accumulate loss scaled by batch size\n",
        "    avg_loss = total_loss / len(train_loader.dataset)\n",
        "    print(f\"Training Loss: {avg_loss:.4f}\")\n",
        "    return avg_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_regulator(model,train_loader,val_loader, optimizer, device, num_epochs):\n",
        "    \"\"\"Trains the model with periodic evaluation.\n",
        "    \n",
        "     :param model: The model to train.\n",
        "     :param train_loader: DataLoader providing batches of (input_batch, target_batch).\n",
        "     :param val_loader: DataLoader for validation data.\n",
        "     :param optimizer: The optimizer to use for training.\n",
        "     :param device: The device (CPU or GPU) to perform computations on.\n",
        "     :param num_epochs: Number of epochs to train.\"\"\"\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    step = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, device)\n",
        "        step += 1\n",
        "        print(f\"Completed epoch {epoch+1}/{num_epochs}\")\n",
        "        # Evaluate every 10 steps\n",
        "        if step % 10 == 0:\n",
        "            val_auc = cal_auc_loader(model, val_loader, device)\n",
        "            val_loss = calc_loss_loader(model, val_loader, device)\n",
        "            train_losses.append(train_loss)\n",
        "            val_losses.append(val_loss)\n",
        "            print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val AUC: {val_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"/kaggle/input/jigsaw-agile-community-rules/train.csv\")\n",
        "test = pd.read_csv(\"/kaggle/input/jigsaw-agile-community-rules/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CommentDataset(Dataset):\n",
        "    \"\"\"Custom Dataset for loading comments and their labels.\"\"\"\n",
        "    def __init__(self, tokensizer, df, max_length=1024):\n",
        "        \"\"\"Initialize the dataset with texts and labels.\n",
        "\n",
        "        :param tokenizer: Tokenizer to convert text to tokens.\n",
        "        :param df: DataFrame containing the data.\n",
        "        :param max_length: Maximum length for tokenization. Default is 1024.\n",
        "        \"\"\"\n",
        "        self.tokenizer = tokensizer\n",
        "        self.max_length = max_length \n",
        "        self.texts = [f\"Predict if this subredit with following Body: {row.body} would violates this Rule: {row.rule} I am providing you two Positive Examples: {row.positive_example_1} {row.positive_example_2} and two Negative Examples: {row.negative_example_1}, {row.negative_example_2} You can learn from these examples and predict 1 for yes and 0 for No.\" \n",
        "                        for row in df.itertuples(index=False)]\n",
        "        \n",
        "        # Batch encode once during initialization\n",
        "        self.encodings = self.tokenizer(\n",
        "            self.texts,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        self.labels = torch.tensor(df['rule_violation'].values, dtype=torch.long)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            self.encodings['input_ids'][idx],\n",
        "            self.labels[idx] \n",
        "            )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = CommentDataset(tokenizer, train.iloc[50:,:])\n",
        "val_dataset = CommentDataset(tokenizer, train.iloc[:50,:])\n",
        "\n",
        "batch_size = 8\n",
        "train_loader = DataLoader(\n",
        "        train_dataset, \n",
        "        batch_size=batch_size, \n",
        "        shuffle=True, \n",
        "        drop_last=True,\n",
        "        num_workers=4,          \n",
        "        pin_memory=True,        \n",
        "        prefetch_factor=2,\n",
        "        persistent_workers=True)\n",
        "\n",
        "val_loader = DataLoader(\n",
        "        val_dataset, \n",
        "        batch_size=batch_size, \n",
        "        shuffle=False, \n",
        "        num_workers=4,          \n",
        "        pin_memory=True,        \n",
        "        prefetch_factor=2,\n",
        "        persistent_workers=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2029, 9)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(247, 7)"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_loader), len(val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input IDs shape: torch.Size([8, 1024])\n",
            "Labels shape: torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "for input_ids, labels in train_loader:\n",
        "    print(\"Input IDs shape:\", input_ids.shape)\n",
        "    print(\"Labels shape:\", labels.shape)\n",
        "    calc_loss_loader(model, val_loader, device)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 5.6903\n",
            "Completed epoch 1/3\n",
            "Training Loss: 5.5928\n",
            "Completed epoch 2/3\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
        "train_regulator(model,train_loader,val_loader, optimizer, device, 3)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "S5E6-XGBoost-0601",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
